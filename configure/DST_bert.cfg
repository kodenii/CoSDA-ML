[model]
name = DST.all
test = False

[dataset]
src = WOZ/woz_en_small
tool = WOZ.all
dontcare_src = dontcare
dontcare_tgt_it = non importa
dontcare_tgt_de = es ist egal
dict = Panlex/dict/it2.txt Panlex/dict/de2.txt

[lr]
default = 1e-3
bert = 1e-5

[pred]
threshold = 0.5

[multi_bert]
location = bert-base-multilingual-cased

[train]
epoch = 100
batch = 32
seed = 42
gpu = False
max_save = 5
ratio = 1.0
cross = 0.9
stop = joint_goal